{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = os.path.join(\"ray_tuner/run1_0\")\n",
    "print(f\"Loading results from {experiment_path}...\")\n",
    "\n",
    "def run(config):  \n",
    "    '''\n",
    "    Training function. Gets dictionary of tunable hyperparameters as an input.\n",
    "    '''\n",
    "    train_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = \"cpu\"\n",
    "    print(f\"Device: {train_device}\")\n",
    "    play_device = \"cpu\" # This is much faster on cpu, even if training with GPU, as it minimizes overhead\n",
    "\n",
    "    # Tunable hyperparameters\n",
    "    GAMMA=0.9\n",
    "    LAMBDA_=0.9\n",
    "    hidden_size = 80\n",
    "    lr_actor = config[\"alr\"]\n",
    "    lr_critic = config[\"clr\"]\n",
    "    n_rollouts = 3\n",
    "    n_batches = 10\n",
    "    n_updates_per_iter = 10\n",
    "    emb_size = 60\n",
    "    EPS_N = 2_000_000\n",
    "    EPS_N_normed = int(EPS_N/n_rollouts/n_batches)\n",
    "    scheduler_lmbd= config[\"sched_lmbd\"]\n",
    "    eps_clip = 0.13\n",
    "    entropy_scale = 7.5e-3\n",
    "    entropy_steepness = config[\"e_st\"] \n",
    "\n",
    "    id_string = \"\"\n",
    "    \n",
    "    for key, value in config.items():\n",
    "        try:\n",
    "            sci_value = \"{:.1e}\".format(float(value))\n",
    "            id_string += f\"{key}{sci_value}_\"\n",
    "        except (ValueError, TypeError):\n",
    "            # If value can't be converted to float, use original value\n",
    "            id_string += f\"{key}{value}_\"\n",
    "    # Remove the trailing comma and space if the string isn't empty\n",
    "    id_string = id_string[:-2]\n",
    "\n",
    "    identifier=\"V1-0_\"+id_string\n",
    "    \n",
    "    # Load training net\n",
    "    round_n=5\n",
    "    card_n=5\n",
    "    bet_n=3\n",
    "    player_n=2\n",
    "    n_inputs = card_n + player_n*(1+round_n) + player_n \n",
    "    n_outputs = 52+bet_n\n",
    "    Actor = model.Actor(n_inputs,hidden_size,n_outputs,emb_size).to(train_device)\n",
    "    Critic = model.Critic(n_inputs,hidden_size,emb_size).to(train_device)\n",
    "\n",
    "    # Load enemy\n",
    "    enemy_net = model.Actor(n_inputs,hidden_size,n_outputs,emb_size)\n",
    "    load_dict = torch.load(os.path.join(script_dir,r\"model/trained_actor_V1-0.pt\"))\n",
    "    enemy_net.load_state_dict(load_dict[\"model_state\"])\n",
    "    enemy = AI(\"XXX_SLAYAH_XXX\",enemy_net,play_device)\n",
    "\n",
    "    # Set optimizers\n",
    "    actor_optim = optim.Adam(Actor.parameters(),lr=lr_actor,foreach=True)\n",
    "    critic_optim = optim.Adam(Critic.parameters(),lr=lr_critic,foreach=True)\n",
    "    actor_scheduler = lr_scheduler.StepLR(actor_optim,step_size=max(1,EPS_N_normed//40),gamma=scheduler_lmbd)\n",
    "    critic_scheduler = lr_scheduler.StepLR(critic_optim,step_size=max(1,EPS_N_normed//40),gamma=scheduler_lmbd)\n",
    "\n",
    "    ME = Agent(identifier,EPS_N_normed,Actor,Critic,play_device,train_device,actor_optim,critic_optim,actor_scheduler,critic_scheduler,GAMMA,LAMBDA_,eps_clip,enemy,n_rollouts,n_batches,n_updates_per_iter,entropy_scale,entropy_steepness)\n",
    "    policy_net = ME.learn()\n",
    "\n",
    "    [print(f\"{key}: {np.array(value).mean()}\") for key,value in times.items()]\n",
    "\n",
    "restored_tuner = tune.Tuner.restore(experiment_path,trainable=run)\n",
    "result_grid = restored_tuner.get_results()\n",
    "#result_grid.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "print(f\"Results: {len(result_grid)}\")\n",
    "for result in result_grid:\n",
    "    if result.config is not None:\n",
    "        config = result.config\n",
    "        winrate = result.metrics_dataframe.winrate.max()\n",
    "        id_string = \"\"\n",
    "    \n",
    "        for key, value in config.items():\n",
    "            try:\n",
    "                sci_value = \"{:.1e}\".format(float(value))\n",
    "                id_string += f\"{key}{sci_value}_\"\n",
    "            except (ValueError, TypeError):\n",
    "                # If value can't be converted to float, use original value\n",
    "                id_string += f\"{key}{value}_\"\n",
    "        # Remove the trailing comma and space if the string isn't empty\n",
    "        id_string = id_string[:-1]\n",
    "\n",
    "        label=id_string\n",
    "        if winrate > 0.0:\n",
    "            if ax is None:\n",
    "                ax = result.metrics_dataframe.plot(\"training_iteration\", \"winrate\", label=label)\n",
    "            else:\n",
    "                result.metrics_dataframe.plot(\"training_iteration\", \"winrate\", ax=ax, label=label)\n",
    "ax.set_title(\"Winrate vs. Training Iteration for All Trials\")\n",
    "ax.set_ylabel(\"Winrate\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tikki import Tikki\n",
    "from player import player,AI, random_win_player, random_player\n",
    "import model_relu_deep_skip as model\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "# Example usage\n",
    "n_players = 2\n",
    "round_n = 5\n",
    "card_n = 5\n",
    "n_bets = 3\n",
    "n_inputs = card_n + n_players*(1+round_n) + n_players\n",
    "n_outputs = 52+3\n",
    "\n",
    "# LOAD ME\n",
    "Actor = model.Actor(n_inputs,80,n_outputs,60)\n",
    "model_folder_path = \"\"\n",
    "file_name = os.path.join(model_folder_path)\n",
    "load_dict = torch.load(file_name)\n",
    "Actor.load_state_dict(load_dict[\"model_state\"])\n",
    "\n",
    "# LOAD ENEMY\n",
    "enemy_net = model.Actor(n_inputs,80, n_outputs,emb_size=60)\n",
    "model_folder_path = \"\"\n",
    "file_name = os.path.join(model_folder_path)\n",
    "thing = torch.load(file_name)\n",
    "enemy_net.load_state_dict(thing[\"model_state\"])\n",
    "\n",
    "N_games = 100\n",
    "winners = []\n",
    "me = AI(\"tappaja\",Actor,\"cpu\")\n",
    "enemy = random_player(\"xslayx\")\n",
    "\n",
    "players = [enemy,me]\n",
    "\n",
    "passes = []\n",
    "def run_agent_simulation():\n",
    "    for i in range(N_games):\n",
    "        game = Tikki(players)\n",
    "        game.new_game()\n",
    "        \n",
    "        while 1:\n",
    "            action, state, reward, done,_ = game.step(me)\n",
    "            #print(action)\n",
    "            if action in torch.tensor([52,53,54]):\n",
    "                passes.append(action)\n",
    "                    \n",
    "            if done:\n",
    "                    winners.append(game.game_winner == me)\n",
    "                    #print(game.game_winner)\n",
    "                    break\n",
    "\n",
    "run_agent_simulation()\n",
    "\n",
    "wins = copy.deepcopy(winners)\n",
    "wins = np.array(wins)\n",
    "wins_mean = wins.mean()\n",
    "print(wins_mean)\n",
    "print(f\"Pass: {100*(np.array(passes) == 52).sum()/len(passes):.2f}%, Win: {100*(np.array(passes) == 53).sum()/len(passes):.2f}%, 2-Win; {100*(np.array(passes) == 54).sum()/len(passes):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tikkiAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
